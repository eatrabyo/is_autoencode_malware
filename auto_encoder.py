import numpy as np
from tensorflow.keras.layers import Dense,Normalization,InputLayer
from tensorflow.keras import Sequential
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ReduceLROnPlateau
import tensorflow as tf
import random
import matplotlib.pyplot as plt
import wandb
from wandb.keras import WandbMetricsLogger

from scaler import scaler

config = {
        "layer_1": 2000,
        "layer_2": 1800,
        "layer_3": 1600,
        "layer_4": 1400,
        "layer_5": 1200,
        "layer_6": 1000,
        "layer_7": 800,
        "layer_8": 600,
        "layer_9": 400,
        "origin": 2381,
        "relu": "relu",
        "sigmoid": "sigmoid",
        "leaky_relu":tf.keras.layers.LeakyReLU(),
        "optimizer": tf.keras.optimizers.legacy.Adam(learning_rate=0.0001),
        "loss": tf.keras.losses.MeanAbsoluteError(),
        "metric": tf.keras.metrics.MeanAbsoluteError(),
        "epoch": 1,
        "batch_size": 64,
        "min_lr": 0.00005,
        "reduce_lr_patience": 20
    }
run = wandb.init(project="autoencoder_malware", config=config)

class StackAE(Model):
    def __init__(self):
        super(StackAE,self).__init__()
        
        self.encoder = Sequential([
            Dense(config['layer_1'], activation = config['leaky_relu'], input_shape = (config['origin'],)),
            Dense(config['layer_2'], activation = config['leaky_relu']),
            Dense(config['layer_3'], activation = config['leaky_relu']),
            Dense(config['layer_4'], activation = config['leaky_relu']),
            Dense(config['layer_5'], activation = config['leaky_relu']),
            Dense(config['layer_6'], activation = config['leaky_relu']),
            Dense(config['layer_7'], activation = config['leaky_relu']),
            Dense(config['layer_8'], activation = config['leaky_relu']),
            Dense(config['layer_9'], activation = config['leaky_relu']),
        ])

        self.decoder = Sequential([
            Dense(config['layer_8'], activation = config['leaky_relu']),
            Dense(config['layer_7'], activation = config['leaky_relu']),
            Dense(config['layer_6'], activation = config['leaky_relu']),
            Dense(config['layer_5'], activation = config['leaky_relu']),
            Dense(config['layer_4'], activation = config['leaky_relu']),
            Dense(config['layer_3'], activation = config['leaky_relu']),
            Dense(config['layer_2'], activation = config['leaky_relu']),
            Dense(config['layer_1'], activation = config['leaky_relu']),
            Dense(config['origin'], activation = 'linear')
        ])

    def call(self,x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded


if __name__ == '__main__':

    print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
    seed = 123
    random.seed(seed)
    tf.random.set_seed(seed)
    np.random.seed(seed)

    TRAIN_PATH = 'data/train_set.npz'
    VALID_PATH = 'data/validate_set.npz'
    TEST_PATH = 'data/test_set.npz'

    train_set = np.load(TRAIN_PATH)
    valid_set = np.load(VALID_PATH)
    test_set = np.load(TEST_PATH)

    X_train = train_set['x']
    y_train = train_set['y']

    X_valid = valid_set['x']
    y_valid = valid_set['y']

    X_test = test_set['x']
    y_test = test_set['y']

    print(f'X,y dtype\nTrain: {X_train.dtype},{y_train.dtype}\nValidate: {X_valid.dtype},{y_valid.dtype}\nTest: {X_test.dtype},{y_test.dtype}')

    # scaler
    
    """ revised later"""

    X_train_preprocess, X_valid_preprocess, X_test_preprocess = scaler(X_train,X_valid,X_test)

    # convert to tensor
    X_train_preprocess = tf.convert_to_tensor(X_train_preprocess,dtype=tf.float32)
    y_train = tf.convert_to_tensor(y_train,dtype=tf.int32)
    
    X_valid_preprocess = tf.convert_to_tensor(X_valid_preprocess,dtype=tf.float32)
    y_valid = tf.convert_to_tensor(y_valid,dtype=tf.int32)

    X_test_preprocess = tf.convert_to_tensor(X_test_preprocess,dtype=tf.float32)
    y_test = tf.convert_to_tensor(y_test,dtype=tf.int32)

    # model
    autoencoder = StackAE()

    # callback
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=config['reduce_lr_patience'], min_lr=config['min_lr'],verbose=1)
    
    callback_list = [reduce_lr, WandbMetricsLogger(log_freq='epoch')]

    autoencoder.compile(optimizer=config['optimizer'], loss=config['loss'],
                        metrics = [config['metric']])
    
    history = autoencoder.fit(X_train_preprocess, X_train_preprocess,
            epochs = config['epoch'],
            batch_size = config['batch_size'],
            validation_data = (X_valid_preprocess , X_valid_preprocess ),
            shuffle = True, verbose = 2, callbacks = callback_list)
    
    plt.figure(figsize=(12,6))
    plt.subplot(1,2,1)
    plt.plot(history.history["loss"], label="Training Loss")
    plt.plot(history.history["val_loss"], label="Validation Loss")
    plt.legend()
    plt.title('Training and Validation MAE Over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('MAE')

    # plt.subplot(1,2,2)
    # plt.plot(history.history['mean_absolute_error'],label='Training MAE')
    # plt.plot(history.history['val_mean_absolute_error'],label='Validation MAE')

    # plt.plot(history.history['mean_squared_error'],label='Training MSE')
    # plt.plot(history.history['val_mean_squared_error'],label='Validation MSE')

    # plt.legend()
    # plt.title('Training and Validation MAE & MSE Over Epochs')
    # plt.xlabel('Epochs')

    # plt.show()

    test_result = autoencoder.evaluate(X_test_preprocess,X_test_preprocess)
    print(f'{autoencoder.metrics_names}: {test_result}')
    run.finish()

