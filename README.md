# Autoencoder for PE Malware Detection

## Introduction
Malware is a product of human creation, and humans adapt over time. To capture the best feature representation, it is essential to reduce the dimensionality of the data. Autoencoders can be used for dimensionality reduction and feature extraction. The reduced-dimensional data can then be classified using a Deep Neural Network.

## Dataset
The dataset used is [the BODMAS Malware Dataset](https://whyisyoung.github.io/BODMAS/), which includes malware samples collected between 2019 and 2020. It contains 77,142 benign samples and 57,293 malicious samples, with a total of 2,381 features.

## EDA
Benign samples were collected from 2007 to 2020, while malware samples were collected from 2019 to 2020.

![Benign Collected Year](https://github.com/user-attachments/assets/3d5cc4cb-d416-4ae0-83ce-2167f1f19f2c)  |  ![Malware Collected Year](https://github.com/user-attachments/assets/4a6abe03-793c-4699-b043-6abe220ef8fa)
:-------------------------:|:-------------------------:

Malware samples were collected from 14 malware categories. However, the majority are Trojans and worms.


![mal_cat](https://github.com/user-attachments/assets/e34aeeda-a8b4-43ca-ba12-1aa6c3a7d537)  |
:-------------------------:|

## Splitting Data
Out of 134,435 samples, the dataset was split into 80% for training and 20% for testing. The 80% training set was further split into 90% for training and 10% for validation. This resulted in 96,793 samples for the training set, 26,887 samples for the testing set, and 10,755 samples for the validation set.

![mal_split](https://github.com/user-attachments/assets/0ca196d2-0eb9-4443-bafc-4484cd693dd8) |
:-------------------------:|

## Model Training
We preprocessed the data using a Standard Scaler and built two Autoencoder architectures: one that reduces the features to 600, referred to as AE_600, and another that reduces them to 400, referred to as AE_400. We then employed a Deep Neural Network and several conventional machine learning algorithms as classifiers. For benchmarking, we used Random Forest for feature selection and a Deep Neural Network as the classifier. PCA was not selected because reducing the number of features to capture 95% of the variance resulted in excessively high dimensionality.

### Autoencoder
1. AE_600
```python
config = {
        "layer_1": 2300,
        "layer_2": 2000,
        "layer_3": 1700,
        "layer_4": 1400,
        "layer_5": 1100,
        "layer_6": 800,
        "layer_7": 600,
        "origin": 2381,
        "leaky_relu":keras.layers.LeakyReLU(),
        "optimizer": keras.optimizers.Adam(learning_rate=0.0005),
        "loss": keras.losses.MeanAbsoluteError(),
        "metric": keras.metrics.MeanAbsoluteError(),
        "epoch": 100,
        "batch_size": 512,
        "min_lr": 0.00005,
        "reduce_lr_patience": 10
    }

class DeepAE(tf.keras.models.Model):
    def __init__(self, **kwargs):
        super(DeepAE,self).__init__(**kwargs)
        
        self.encoder = keras.Sequential([
            keras.layers.Dense(config['layer_1'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_2'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_3'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_4'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_5'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_6'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_7'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            
        ])

        self.decoder = keras.Sequential([
            keras.layers.Dense(config['layer_6'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_5'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_4'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_3'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_2'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_1'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['origin'], activation = 'linear'),
            keras.layers.BatchNormalization(),
        ])

    def call(self,x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded
    
    def get_config(self):
        config = super().get_config()
        return config
```
2. AE_400
```python
config = {
        "layer_1": 2300,
        "layer_2": 2000,
        "layer_3": 1700,
        "layer_4": 1400,
        "layer_5": 1100,
        "layer_6": 800,
        "layer_7": 600,
        "layer_8": 400,
        "origin": 2381,
        "leaky_relu":keras.layers.LeakyReLU(),
        "optimizer": keras.optimizers.Adam(learning_rate=0.0005),
        "loss": keras.losses.MeanAbsoluteError(),
        "metric": keras.metrics.MeanAbsoluteError(),
        "epoch": 100,
        "batch_size": 512,
        "min_lr": 0.00005,
        "reduce_lr_patience": 10
    }

class DeepAE(tf.keras.models.Model):
    def __init__(self, **kwargs):
        super(DeepAE,self).__init__(**kwargs)
        
        self.encoder = keras.Sequential([
            keras.layers.Dense(config['layer_1'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_2'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_3'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_4'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_5'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_6'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_7'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_8'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            
        ])

        self.decoder = keras.Sequential([
            keras.layers.Dense(config['layer_7'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_6'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_5'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_4'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_3'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_2'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['layer_1'], activation = config['leaky_relu']),
            keras.layers.BatchNormalization(),
            keras.layers.Dense(config['origin'], activation = 'linear'),
            keras.layers.BatchNormalization(),
        ])

    def call(self,x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded
    
    def get_config(self):
        config = super().get_config()
        return config
```
### Classifier
Deep Neural Network
```python
def classifier(no_features,compile=True):
    model = keras.Sequential([
        keras.layers.InputLayer(input_shape = (no_features,)),
        keras.layers.Dense(400, activation=keras.layers.LeakyReLU(),name="dense_1"),
        keras.layers.BatchNormalization(name="batch_norm_1"),
        keras.layers.Dense(300, activation=keras.layers.LeakyReLU(),name="dense_2"),
        keras.layers.BatchNormalization(name="batch_norm_2"),
        keras.layers.Dense(200, activation=keras.layers.LeakyReLU(),name="dense_3"),
        keras.layers.BatchNormalization(name="batch_norm_3"),
        keras.layers.Dense(100, activation=keras.layers.LeakyReLU(),name="dense_4"),
        keras.layers.BatchNormalization(name="batch_norm_4"),
        keras.layers.Dense(50, activation=keras.layers.LeakyReLU(),name="dense_5"),
        keras.layers.BatchNormalization(name="batch_norm_5"),
        keras.layers.Dense(25, activation=keras.layers.LeakyReLU(),name="dense_6"),
        keras.layers.BatchNormalization(name="batch_norm_6"),
        keras.layers.Dense(12, activation=keras.layers.LeakyReLU(),name="dense_7"),
        keras.layers.BatchNormalization(name="batch_norm_7"),
        keras.layers.Dense(1, activation='sigmoid',name="dense_8")
    ])

    if compile == True:
        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=keras.losses.BinaryCrossentropy(),
                    metrics = [
                        keras.metrics.BinaryAccuracy(name = 'Binary Accuracy',threshold=0.5),
                        ])
        return model
    if compile == False:
        return model
```

### Training Method
After experimenting with different hyperparameters, the table below shows the best results we achieved.
|                               |     Autoencoder     |  Deep Neural Network |
|:-----------------------------:|:-------------------:|:--------------------:|
|           Optimizer           |         Adam        |         Adam         |
|              Loss             | Mean Absolute Error | Binary Cross-entropy |
|             Epoch             |         100         |          50          |
|           Batch Size          |         512         |          512         |
|         Learning Rate         |        0.0005       |        0.0001        |
|        Layer Activation       |      Leaky Relu     |  Leaky Relu, Sigmoid |
|  Reduce learning Rate Factor  |         0.2         |          0.2         |
|       Min Learning Rate       |       0.00005       |        0.00005       |
| Reduce Learning Rate Patience |          10         |          15          |

## Evaluation
We will focus on the Recall, False Negative Rate, and False Positive Rate metrics. However, Accuracy, Precision, and F1 scores will also be presented.

### Autoencoder Learning Curves
The learning curves from both autoencoders show that the loss between the training and validation sets is closely aligned, indicating that neither autoencoder was overfitting.

![ae_loss](https://github.com/user-attachments/assets/a1f10351-dd5e-4a2c-8fb4-bb04a7227cb3)

### Deep Neural Network Learning Curves
The figures below display the learning curves from three different models used to reduce dimensionality and classify malware with the same deep neural network. Both figures indicate that there is no overfitting in our models.

![nn_train_loss_acc](https://github.com/user-attachments/assets/e1521bcf-6090-4516-a845-dead4b64b6db)

![nn_val_loss_acc](https://github.com/user-attachments/assets/7d0e9dab-9cd4-4916-bfcc-b696808fb1da)

### Runtime
In terms of runtime, AE_600 is the fastest autoencoder. However, when using a Deep Neural Network, Random Forest is the fastest. In each run, Random Forest selected a different number of features, with an average of 457 features being used.

|     Model    | Autoencoder Average Runtime | Deep Neural Network Average Runtime | Average Feature Used |
|:------------:|:---------------------------:|:-----------------------------------:|:--------------------:|
| randomforest |              -              |         00:18:53 ± 00:00:14         |     457 ± 12.1244    |
|    ae_600    |     01:04:53 ± 00:01:28     |         00:21:19 ± 00:00:13         |     600 ± 0.0000     |
|    ae_400    |     01:13:46 ± 00:00:24     |         00:22:09 ± 00:00:27         |     400 ± 0.0000     |

### Test Performance
Random Forest scores highly in every metric. AE_600 performs comparably but shows only a slight improvement in Recall and False Negative Rate.

|        Model        |     Accuracy    |        F1       |        Recall       |    Precision    | False Positive Rate | False Negative Rate |
|:-------------------:|:---------------:|:---------------:|:-------------------:|:---------------:|:-------------------:|:-------------------:|
| Random Forest + DNN | 0.9949 ± 0.0005 | 0.9940 ± 0.0006 |   0.9934 ± 0.0007   | 0.9947 ± 0.0008 |     61 ± 9.5394     |     76 ± 7.8102     |
|     ae_600 + DNN    | 0.9944 ± 0.0003 | 0.9935 ± 0.0004 | **0.9935 ± 0.0003** | 0.9935 ± 0.0007 |     75 ± 7.5498     |   **75 ± 2.8868**   |
|     ae_400 + DNN    | 0.9939 ± 0.0003 | 0.9928 ± 0.0004 |   0.9927 ± 0.0010   | 0.9929 ± 0.0016 |     81 ± 18.5203    |     83 ± 11.9304    |

AE_600 performs the best among the autoencoders. Therefore, we decided to test different classifiers using conventional machine learning methods.
The results did not surpass those of the Deep Neural Network, but AE_600 with Random Forest as the classifier achieved the lowest False Positive Rate.

|          Model         |     Accuracy    |        F1       |      Recall     |    Precision    | False Positive Rate | False Negative Rate |
|:----------------------:|:---------------:|:---------------:|:---------------:|:---------------:|:-------------------:|:-------------------:|
| ae_600 + Decision Tree | 0.9789 ± 0.0015 | 0.9753 ± 0.0018 | 0.9793 ± 0.0013 | 0.9714 ± 0.0023 |    331 ± 27.0062    |    237 ± 14.3643    |
| ae_600 + Logistic Reg. | 0.9867 ± 0.0010 | 0.9844 ± 0.0011 | 0.9844 ± 0.0017 | 0.9844 ± 0.0012 |    178 ± 14.2244    |    179 ± 19.5533    |
| ae_600 + Random Forest | 0.9920 ± 0.0003 | 0.9906 ± 0.0003 | 0.9845 ± 0.0004 | 0.9968 ± 0.0003 |   **36 ± 3.7859**   |     178 ± 4.3589    |
|    ae_600 + RBF SVM    | 0.9923 ± 0.0002 | 0.9909 ± 0.0003 | 0.9880 ± 0.0004 | 0.9938 ± 0.0005 |     71 ± 5.6862     |     137 ± 4.3589    |

## Conclusion
Although AE_600 did not significantly outperform Random Forest, there is still room for improvement in the Autoencoder approach. Random Forest + DNN had lower runtime and used fewer features. While Autoencoders are effective for data types like BODMAS, the challenge is to reduce runtime without increasing the number of features in the encoder's output.
